{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation\n",
    "\n",
    "\n",
    "The used data set can be found at ../data or under http://mfm.uni-leipzig.de/dt/Forschung/CDV2018.php.\n",
    "\n",
    "**Example data point (shortened):**\n",
    "\n",
    "\"b0339\": {\n",
    "    \n",
    "    \"defaultSurName\": \"Beethoven\",\n",
    "    \"defaultPreName\": \"Ludwig van\",\n",
    "    \"dates\": [\"1770 Dez 16\", \"1827 Mar 27\", ... ],\n",
    "    \"gender\": [\"männlich\"],\n",
    "    \"konfession\": [\"römisch-katholisch\"],\n",
    "    \"musicalJobs\": [\"Komponist\", ...],\n",
    "    \"relation\": {\n",
    "      \"Lehrer\": [{\"target\": \"a0884\", \"displayName\": \"Albrechtsberger, Johann Georg\"}, ...],\n",
    "      \"Schüler\": [{\"target\": \"n0412\", \"displayName\": \"Neukäufler, Ferdinand\"}, ...], ...},\n",
    "    \"places\": [\n",
    "      \"Aschaffenburg\",\n",
    "      \"Bad Mergentheim\", ...\n",
    "    ],\n",
    "    \"mainPlace\": \"Wien\",\n",
    "    \"links\": [ [\n",
    "        \"Biographien/Karrieren\",\n",
    "        {\n",
    "          \"Akten der Reichskanzlei der Weimarer Republik\": [\n",
    "            {\"displayName\": \"Akten der Reichskanzlei der Weimarer Republik (1)\", \"target\":                                        [\"http://www.bundesarchiv.de/aktenreichskanzlei/1919-1933/0000/adr/getPPN/118508288/\"]} ], ...\n",
    "    ],\n",
    "    \"mapPlaces\": [ [\"Wien\", \"48.208174\", \"16.373819\", \"9.\"], ...] \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading\n",
    "\n",
    "The first step is reading in the data set, consisting of 26 json files, which separate the persons according to the first letter of their last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading the data\n",
    "'''\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "path = \"data/Personen/\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "for file in os.listdir(path):      # the path contains 26 json files\n",
    "    \n",
    "    with open(path + file, encoding='utf-8') as f:\n",
    "        x = json.load(f)\n",
    "        \n",
    "    for key in x:              # we don't need the 'links' attribute for our analysis\n",
    "        x[key].pop('links', None) \n",
    "        \n",
    "    data.update(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conversion\n",
    "\n",
    "Once the metadata dictionary is extracted, we convert the data into a more easily readable format. In addition to the obvious attributes, we extract an 'era' attribute, which refers to the Western classical music eras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyuba/plotly/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/lyuba/plotly/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Attribute extraction\n",
    "'''\n",
    "\n",
    "import re\n",
    "     \n",
    "# western music eras \n",
    "music_era = {'Medieval': range(500, 1400), 'Renaissance': range(1400, 1600), 'Baroque': range(1600, 1750), \n",
    "             'Classical': range(1750, 1820), 'Romantic': range(1820, 1910), \n",
    "             'Modern': range(1910, 1975), 'Contemporary': range(1975, 2018)}\n",
    "\n",
    "\n",
    "def get_node_attributes(person):\n",
    "    attr = {}\n",
    "    info = data[person]\n",
    "    \n",
    "    # name\n",
    "    prename = info[\"defaultPreName\"]\n",
    "    surname = info[\"defaultSurName\"]\n",
    "    if prename and surname:\n",
    "        attr['name'] = ' '.join([prename, surname])\n",
    "    elif prename:\n",
    "        attr['name'] = prename\n",
    "    elif surname:\n",
    "        attr['name'] = surname\n",
    "        \n",
    "    # gender\n",
    "    attr['gender'] = info[\"gender\"][0] if info[\"gender\"] else 'unknown'\n",
    "    \n",
    "    # religion\n",
    "    attr['religion'] = info['konfession'][0] if info['konfession'] else 'unknown'\n",
    "    \n",
    "    # music jobs\n",
    "    clean_music_jobs = [job for job in info['musicalJobs'] if job]   # filters out nulls\n",
    "    attr['musicJobs'] = ','.join(clean_music_jobs) if clean_music_jobs else 'none'\n",
    "\n",
    "    # other jobs\n",
    "    clean_other_jobs = [job for job in info['otherJobs'] if job]   # filters out nulls\n",
    "    attr['otherJobs'] = ','.join(clean_other_jobs) if clean_other_jobs else 'none'\n",
    "        \n",
    "    # workplaces - Wirkungsorte\n",
    "    attr['workPlace'] = ','.join(info['places']) if info['places'] else 'unknown'\n",
    "    \n",
    "    # main workplace - Hauptwirkungsort\n",
    "    attr['mainPlace'] = info['mainPlace'] if info['mainPlace'] else 'unknown'\n",
    "    \n",
    "    # year of birth \n",
    "    attr[\"birthYear\"] = int(re.search('[0-9]{3,4}', info[\"dates\"][0]).group(0)) if info[\"dates\"][0] else 0\n",
    "\n",
    "    # year of death\n",
    "    try:                            \n",
    "        attr[\"deathYear\"] = int(re.search('[0-9]{3,4}', info[\"dates\"][2]).group(0)) if info[\"dates\"][2] else 3000\n",
    "    except AttributeError:\n",
    "        attr[\"deathYear\"] = 3000                 # BAD DATA POINT; birthPlace given instead of deathYear\n",
    "        attr[\"birthPlace\"] = info[\"dates\"][2] if info[\"dates\"][2] else 'unknown'\n",
    "    \n",
    "    # place of birth\n",
    "    attr[\"birthPlace\"] = info[\"dates\"][4] if info[\"dates\"][4] else 'unknown'\n",
    "    \n",
    "    # place of death\n",
    "    attr[\"deathPlace\"] = info[\"dates\"][5] if info[\"dates\"][5] else 'unknown'    \n",
    "    \n",
    "    # era\n",
    "    for era in music_era:\n",
    "        if attr['deathYear'] in music_era[era]:\n",
    "            attr['era'] = era\n",
    "            \n",
    "    if 'era' not in attr:\n",
    "        for era in music_era:\n",
    "            if (attr['birthYear'] + 30) in music_era[era]:\n",
    "                attr['era'] = era\n",
    "                \n",
    "    if 'era' not in attr:\n",
    "        attr['era'] = 'unknown'\n",
    "            \n",
    "    return attr\n",
    "\n",
    "\n",
    "'''\n",
    "Cleaning the data\n",
    "'''\n",
    "\n",
    "clean_data = {person: get_attributes(person) for person in data}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph creation\n",
    "\n",
    "We create a directed graph from the data with the Python module networkx. The module makes it possible to export the graph to a Gephi-readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the graph\n",
    "'''\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "g = nx.DiGraph()\n",
    "\n",
    "for person in data: \n",
    "    \n",
    "    attribs = clean_data[person]\n",
    "    g.add_node(person, **attribs)\n",
    "    \n",
    "    rels = data[person]['relation']     # all relations that person has\n",
    "    \n",
    "    for rel in rels:                    # add the relation to the graph as an edge between two persons\n",
    "        for other_person in rels[rel]:\n",
    "            if other_person['target'] in data:\n",
    "                g.add_edge(person, other_person['target'], relation=rel)\n",
    "                \n",
    "                \n",
    "'''\n",
    "Exporting the graph \n",
    "'''\n",
    "\n",
    "nx.write_gexf(g, 'graph_full.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pickling\n",
    "\n",
    "In order to avoid reading in all json files and converting the data more than once, we pickle the objects we will need for our analysis. Converting the attributes dictionary to a DataFrame will further simplify later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "pickle.dump(data, open('../pickled/person_dict.p', 'wb'))\n",
    "\n",
    "df = pd.DataFrame(clean_data).T     # transposing, so that the person ids act as indices instead of as columns\n",
    "df.to_pickle('../pickled/dataframed_attributes.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
